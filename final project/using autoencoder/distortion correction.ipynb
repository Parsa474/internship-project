{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9299685c-a18b-4d12-8ea0-40b31a7c1d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.001173865981400013\n",
      "Epoch [2/10], Loss: 0.0008981645805761218\n",
      "Epoch [3/10], Loss: 0.0007116715423762798\n",
      "Epoch [4/10], Loss: 0.0005352162988856435\n",
      "Epoch [5/10], Loss: 0.0004613377386704087\n",
      "Epoch [6/10], Loss: 0.0003921545285265893\n",
      "Epoch [7/10], Loss: 0.0004295187536627054\n",
      "Epoch [8/10], Loss: 0.00035062237293459475\n",
      "Epoch [9/10], Loss: 0.00038911346928216517\n",
      "Epoch [10/10], Loss: 0.0003200152132194489\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, num_images=5):\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(10, 4))\n",
    "    for i in range(num_images):\n",
    "        axes[0, i].imshow(images[0][i].squeeze(0).cpu().detach().numpy(), cmap='gray')\n",
    "        axes[1, i].imshow(images[1][i].squeeze(0).cpu().detach().numpy(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Define a simple autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Create a DataLoader for the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Instantiate the autoencoder\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        images, _ = batch\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Test the autoencoder by reconstructing images\n",
    "# test_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_loader:\n",
    "#         images, _ = batch\n",
    "#         images = images.to(device)\n",
    "#         reconstructed_images = autoencoder(images)\n",
    "#         show_images([images, reconstructed_images])\n",
    "\n",
    "# Save the trained autoencoder model\n",
    "torch.save(autoencoder.state_dict(), 'autoencoder_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044aad1-e24b-4ec5-9e5e-f57f135ae350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
